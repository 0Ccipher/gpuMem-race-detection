//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34385749
// Cuda compilation tools, release 12.5, V12.5.82
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_60
.address_size 64

	// .globl	_Z10initKernelv
.global .align 4 .b8 head[40];
.global .align 4 .b8 tail[40];
.global .align 4 .b8 edgeSetU[40];
.global .align 4 .b8 edgeSetV[40];
.global .align 4 .b8 graphComponents[40];
.global .align 4 .b8 bases[40];
.global .align 4 .b8 blockIds[40];

.visible .entry _Z10initKernelv()
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<33>;
	.reg .b64 	%rd<25>;


	mov.u32 	%r1, %tid.x;
	mov.u32 	%r32, %ctaid.x;
	cvt.s64.s32 	%rd1, %r32;
	mul.wide.s32 	%rd4, %r32, 4;
	mov.u64 	%rd5, bases;
	add.s64 	%rd2, %rd5, %rd4;
	mov.u64 	%rd6, blockIds;
	add.s64 	%rd3, %rd6, %rd4;
	setp.ne.s32 	%p1, %r1, 0;
	@%p1 bra 	$L__BB0_2;

	shl.b64 	%rd7, %rd1, 2;
	mov.u64 	%rd8, head;
	add.s64 	%rd9, %rd8, %rd7;
	atom.global.add.u32 	%r16, [%rd9], 2;
	st.global.u32 	[%rd2], %r16;
	atom.global.cta.exch.b32 	%r17, [%rd3], %r32;

$L__BB0_2:
	bar.sync 	0;
	shl.b64 	%rd10, %rd1, 2;
	mov.u64 	%rd11, tail;
	add.s64 	%rd12, %rd11, %rd10;
	ld.global.u32 	%r31, [%rd12];
	ld.global.u32 	%r29, [%rd2];
	setp.ge.s32 	%p2, %r29, %r31;
	@%p2 bra 	$L__BB0_13;

	mov.u64 	%rd14, graphComponents;
	mov.u64 	%rd17, head;

$L__BB0_4:
	add.s32 	%r8, %r29, %r1;
	setp.ge.s32 	%p3, %r8, %r31;
	@%p3 bra 	$L__BB0_6;

	mul.wide.s32 	%rd13, %r8, 4;
	add.s64 	%rd15, %rd14, %rd13;
	st.global.u32 	[%rd15], %r8;

$L__BB0_6:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_8;

	mul.wide.s32 	%rd16, %r32, 4;
	add.s64 	%rd18, %rd17, %rd16;
	atom.global.add.u32 	%r18, [%rd18], 2;
	st.global.u32 	[%rd2], %r18;

$L__BB0_8:
	bar.sync 	0;
	ld.global.u32 	%r29, [%rd2];
	setp.lt.s32 	%p5, %r29, %r31;
	@%p5 bra 	$L__BB0_12;

	bar.sync 	0;
	@%p1 bra 	$L__BB0_11;

	add.s32 	%r19, %r32, 1;
	shr.u32 	%r20, %r19, 31;
	add.s32 	%r21, %r19, %r20;
	and.b32  	%r22, %r21, -2;
	sub.s32 	%r23, %r19, %r22;
	mul.wide.s32 	%rd19, %r23, 4;
	add.s64 	%rd21, %rd17, %rd19;
	atom.global.add.u32 	%r24, [%rd21], 0;
	atom.global.add.u32 	%r25, [%rd21], 2;
	st.global.u32 	[%rd2], %r25;
	atom.global.cta.exch.b32 	%r26, [%rd3], %r23;

$L__BB0_11:
	bar.sync 	0;
	atom.global.cta.add.u32 	%r32, [%rd3], 0;
	ld.global.u32 	%r29, [%rd2];
	mul.wide.s32 	%rd22, %r32, 4;
	add.s64 	%rd24, %rd11, %rd22;
	ld.global.u32 	%r31, [%rd24];

$L__BB0_12:
	setp.lt.s32 	%p7, %r29, %r31;
	@%p7 bra 	$L__BB0_4;

$L__BB0_13:
	ret;

}
	// .globl	_Z10linkKernelv
.visible .entry _Z10linkKernelv()
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<48>;
	.reg .b64 	%rd<40>;


	mov.u32 	%r1, %tid.x;
	mov.u32 	%r47, %ctaid.x;
	cvt.s64.s32 	%rd1, %r47;
	mul.wide.s32 	%rd5, %r47, 4;
	mov.u64 	%rd6, bases;
	add.s64 	%rd2, %rd6, %rd5;
	mov.u64 	%rd7, blockIds;
	add.s64 	%rd3, %rd7, %rd5;
	setp.ne.s32 	%p1, %r1, 0;
	@%p1 bra 	$L__BB1_2;

	shl.b64 	%rd8, %rd1, 2;
	mov.u64 	%rd9, head;
	add.s64 	%rd10, %rd9, %rd8;
	atom.global.add.u32 	%r23, [%rd10], 2;
	st.global.u32 	[%rd2], %r23;
	atom.global.cta.exch.b32 	%r24, [%rd3], %r47;

$L__BB1_2:
	bar.sync 	0;
	shl.b64 	%rd11, %rd1, 2;
	mov.u64 	%rd12, tail;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.u32 	%r45, [%rd13];
	ld.global.u32 	%r41, [%rd2];
	setp.ge.s32 	%p2, %r41, %r45;
	@%p2 bra 	$L__BB1_15;

	mov.u64 	%rd15, edgeSetU;
	mov.u64 	%rd17, edgeSetV;

$L__BB1_4:
	add.s32 	%r8, %r41, %r1;
	setp.ge.s32 	%p3, %r8, %r45;
	@%p3 bra 	$L__BB1_8;

	mul.wide.s32 	%rd14, %r8, 4;
	add.s64 	%rd16, %rd15, %rd14;
	add.s64 	%rd18, %rd17, %rd14;
	ld.global.u32 	%r25, [%rd18];
	ld.global.u32 	%r26, [%rd16];
	mul.wide.s32 	%rd19, %r26, 4;
	mov.u64 	%rd20, graphComponents;
	add.s64 	%rd21, %rd20, %rd19;
	atom.global.add.u32 	%r44, [%rd21], 0;
	mul.wide.s32 	%rd22, %r25, 4;
	add.s64 	%rd23, %rd20, %rd22;
	atom.global.add.u32 	%r43, [%rd23], 0;
	setp.eq.s32 	%p4, %r44, %r43;
	@%p4 bra 	$L__BB1_8;

$L__BB1_6:
	max.s32 	%r27, %r44, %r43;
	sub.s32 	%r28, %r43, %r27;
	add.s32 	%r13, %r28, %r44;
	mul.wide.s32 	%rd24, %r27, 4;
	add.s64 	%rd4, %rd20, %rd24;
	atom.global.cas.b32 	%r29, [%rd4], %r27, %r13;
	setp.eq.s32 	%p5, %r29, %r27;
	setp.eq.s32 	%p6, %r29, %r13;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB1_8;

	atom.global.add.u32 	%r30, [%rd4], 0;
	mul.wide.s32 	%rd26, %r30, 4;
	add.s64 	%rd28, %rd20, %rd26;
	atom.global.add.u32 	%r44, [%rd28], 0;
	mul.wide.s32 	%rd29, %r13, 4;
	add.s64 	%rd30, %rd20, %rd29;
	atom.global.add.u32 	%r43, [%rd30], 0;
	setp.ne.s32 	%p8, %r44, %r43;
	@%p8 bra 	$L__BB1_6;

$L__BB1_8:
	bar.sync 	0;
	@%p1 bra 	$L__BB1_10;

	mul.wide.s32 	%rd31, %r47, 4;
	mov.u64 	%rd32, head;
	add.s64 	%rd33, %rd32, %rd31;
	atom.global.add.u32 	%r31, [%rd33], 2;
	st.global.u32 	[%rd2], %r31;

$L__BB1_10:
	bar.sync 	0;
	ld.global.u32 	%r41, [%rd2];
	setp.lt.s32 	%p10, %r41, %r45;
	@%p10 bra 	$L__BB1_14;

	bar.sync 	0;
	@%p1 bra 	$L__BB1_13;

	add.s32 	%r32, %r47, 1;
	shr.u32 	%r33, %r32, 31;
	add.s32 	%r34, %r32, %r33;
	and.b32  	%r35, %r34, -2;
	sub.s32 	%r36, %r32, %r35;
	mul.wide.s32 	%rd34, %r36, 4;
	mov.u64 	%rd35, head;
	add.s64 	%rd36, %rd35, %rd34;
	atom.global.add.u32 	%r37, [%rd36], 0;
	atom.global.add.u32 	%r38, [%rd36], 2;
	st.global.u32 	[%rd2], %r38;
	atom.global.cta.exch.b32 	%r39, [%rd3], %r36;

$L__BB1_13:
	bar.sync 	0;
	atom.global.cta.add.u32 	%r47, [%rd3], 0;
	ld.global.u32 	%r41, [%rd2];
	mul.wide.s32 	%rd37, %r47, 4;
	add.s64 	%rd39, %rd12, %rd37;
	ld.global.u32 	%r45, [%rd39];

$L__BB1_14:
	setp.lt.s32 	%p12, %r41, %r45;
	@%p12 bra 	$L__BB1_4;

$L__BB1_15:
	ret;

}
	// .globl	_Z14compressKernelv
.visible .entry _Z14compressKernelv()
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<47>;
	.reg .b64 	%rd<33>;


	mov.u32 	%r1, %tid.x;
	mov.u32 	%r46, %ctaid.x;
	cvt.s64.s32 	%rd1, %r46;
	mul.wide.s32 	%rd5, %r46, 4;
	mov.u64 	%rd6, bases;
	add.s64 	%rd2, %rd6, %rd5;
	mov.u64 	%rd7, blockIds;
	add.s64 	%rd3, %rd7, %rd5;
	setp.ne.s32 	%p1, %r1, 0;
	@%p1 bra 	$L__BB2_2;

	shl.b64 	%rd8, %rd1, 2;
	mov.u64 	%rd9, head;
	add.s64 	%rd10, %rd9, %rd8;
	atom.global.add.u32 	%r25, [%rd10], 2;
	st.global.u32 	[%rd2], %r25;
	atom.global.cta.exch.b32 	%r26, [%rd3], %r46;

$L__BB2_2:
	bar.sync 	0;
	shl.b64 	%rd11, %rd1, 2;
	mov.u64 	%rd12, tail;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.u32 	%r44, [%rd13];
	ld.global.u32 	%r38, [%rd2];
	setp.ge.s32 	%p2, %r38, %r44;
	@%p2 bra 	$L__BB2_17;

	mov.u64 	%rd15, graphComponents;
	mov.u64 	%rd25, head;

$L__BB2_4:
	add.s32 	%r8, %r38, %r1;
	setp.ge.s32 	%p3, %r8, %r44;
	@%p3 bra 	$L__BB2_10;

	mul.wide.s32 	%rd14, %r8, 4;
	add.s64 	%rd4, %rd15, %rd14;
	atom.global.add.u32 	%r41, [%rd4], 0;
	mul.wide.s32 	%rd16, %r41, 4;
	add.s64 	%rd17, %rd15, %rd16;
	atom.global.add.u32 	%r40, [%rd17], 0;
	setp.eq.s32 	%p4, %r41, %r40;
	@%p4 bra 	$L__BB2_10;

$L__BB2_6:
	atom.global.cas.b32 	%r27, [%rd4], %r41, %r40;
	setp.eq.s32 	%p5, %r27, %r41;
	@%p5 bra 	$L__BB2_8;
	bra.uni 	$L__BB2_7;

$L__BB2_8:
	mul.wide.s32 	%rd21, %r40, 4;
	add.s64 	%rd23, %rd15, %rd21;
	atom.global.add.u32 	%r15, [%rd23], 0;
	mov.u32 	%r41, %r40;
	mov.u32 	%r40, %r15;
	bra.uni 	$L__BB2_9;

$L__BB2_7:
	atom.global.add.u32 	%r41, [%rd4], 0;
	mul.wide.s32 	%rd18, %r41, 4;
	add.s64 	%rd20, %rd15, %rd18;
	atom.global.add.u32 	%r40, [%rd20], 0;

$L__BB2_9:
	setp.ne.s32 	%p6, %r41, %r40;
	@%p6 bra 	$L__BB2_6;

$L__BB2_10:
	bar.sync 	0;
	@%p1 bra 	$L__BB2_12;

	mul.wide.s32 	%rd24, %r46, 4;
	add.s64 	%rd26, %rd25, %rd24;
	atom.global.add.u32 	%r28, [%rd26], 2;
	st.global.u32 	[%rd2], %r28;

$L__BB2_12:
	bar.sync 	0;
	ld.global.u32 	%r38, [%rd2];
	setp.lt.s32 	%p8, %r38, %r44;
	@%p8 bra 	$L__BB2_16;

	bar.sync 	0;
	@%p1 bra 	$L__BB2_15;

	add.s32 	%r29, %r46, 1;
	shr.u32 	%r30, %r29, 31;
	add.s32 	%r31, %r29, %r30;
	and.b32  	%r32, %r31, -2;
	sub.s32 	%r33, %r29, %r32;
	mul.wide.s32 	%rd27, %r33, 4;
	add.s64 	%rd29, %rd25, %rd27;
	atom.global.add.u32 	%r34, [%rd29], 0;
	atom.global.add.u32 	%r35, [%rd29], 2;
	st.global.u32 	[%rd2], %r35;
	atom.global.cta.exch.b32 	%r36, [%rd3], %r33;

$L__BB2_15:
	bar.sync 	0;
	atom.global.cta.add.u32 	%r46, [%rd3], 0;
	ld.global.u32 	%r38, [%rd2];
	mul.wide.s32 	%rd30, %r46, 4;
	add.s64 	%rd32, %rd12, %rd30;
	ld.global.u32 	%r44, [%rd32];

$L__BB2_16:
	setp.lt.s32 	%p10, %r38, %r44;
	@%p10 bra 	$L__BB2_4;

$L__BB2_17:
	ret;

}

